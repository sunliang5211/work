{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "#导入相关包\n",
    "import os,sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\python\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3044: DtypeWarning: Columns (1,13,15,17,18,19,26,34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#设置路径,读取数据\n",
    "train_savepath = 'D:/data/sun/survival'\n",
    "test_savepath = 'D:/data/sun/survival'\n",
    "model_savepath = 'D:/data/model_file/survival/'\n",
    "result_path = 'D:/data/model_file/survival/'\n",
    "df = pd.read_csv(train_savepath + '/user_ext.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_feaim0():\n",
    "    feaim_list = list(base_model.feature_importance())\n",
    "    feaim0_list = []\n",
    "    for i in range(len(feaim_list)):\n",
    "        if list(base_model.feature_importance())[i] ==  0:\n",
    "            feaim0_list.append(i)\n",
    "        else:\n",
    "            pass\n",
    "    return feaim0_list\n",
    "\n",
    "def str_indexlookup(df):\n",
    "    list1 = []\n",
    "    for i in range(df.shape[1]):\n",
    "        if list(df.dtypes != object)[i]:\n",
    "            pass\n",
    "        else:\n",
    "            list1.append(i)\n",
    "    use_col = list(df.columns[list(set(list(range(df.shape[1])))-set(list1))])\n",
    "    return df.loc[:,use_col]\n",
    "\n",
    "def lgb_cv_fit(alg,useTrainCV=True):\n",
    "    if useTrainCV:\n",
    "        cv_params = alg.get_params()\n",
    "        global cv_results\n",
    "        cv_results = lgb.cv(\n",
    "            cv_params, lgb_train, num_boost_round=alg.get_params()['num_iterations'], nfold=5, \n",
    "            stratified=True, shuffle=True, metrics='binary_logloss',\n",
    "            early_stopping_rounds=50, verbose_eval=50, show_stdv=True, seed=0)\n",
    "        num_iterations = len(cv_results['binary_logloss-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_list = ['L0005','L0006','L0007','L0009','L0010','L0013','L0014','L0015','L0016','L0020','L0022','L0023','L0026','L0030','L0033','L0034','L0035','L0036','L0037','L0038','L0039','L0040','L0041','L0042','L0043','L0044','L0045','L0046','L0047','L0048','L0049','L0050','L0051','L0052','L0053','L0054','L0055','L0056','L0057','L0058','L0059','L0060','L0061','L0065','L0066','L0067','L0068','L0070','L0071','L0072','L0073','L0074','L0075','L0076','L0077','L0078','L0079','L0080','L0081','L0082','L0083','L0112','L0113','L0118','L0119','L0121','L0155','L0156','L0157','L0158','L0159','L0160','L0161','L0162','L0163','L0164','L0165','L0166','L0167','L0168','L0169','L0172','L0173','L0174','L0175','L0176','L0177','L0200','L0221','L0222','L0223','L0224','L0225','L0226','L0227','L0228','L0229','L0230','L0231','L0232','L0233','L0234','L0237','L0238','L0247','L0248','L0249','L0252','L0253','L0254','L0255','L0256','L0084','L0085','L0086','L0087','L0088','L0089','L0090','L0091','L0092','L0093','L0094','L0095','L0096','L0097','L0098','L0099','L0100','L0101','L0102','L0103','L0104','L0105','L0106','L0107','L0108','L0109','L0110','L0111','L0114','L0116','L0117','L0120','L0122','L0123','L0124','L0125','L0126','L0127','L0128','L0129','L0130','L0131','L0132','L0133','L0134','L0135','L0136','L0137','L0138','L0139','L0140','L0141','L0142','L0143','L0144','L0145','L0146','L0147','L0148','L0149','L0150','L0151','L0152','L0153','L0154','L0170','L0171','L0178','L0179','L0180','L0181','L0182','L0183','L0184','L0185','L0186','L0187','L0188','L0189','L0190','L0191','L0192','L0193','L0194','L0195','L0196','L0197','L0198','L0199','L0201','L0202','L0203','L0204','L0205','L0206','L0207','L0208','L0209','L0210','L0211','L0212','L0213','L0214','L0215','L0216','L0217','L0218','L0219','L0220','L0239','L0240','L0241','L0242','L0243','L0244','L0245','L0246','L0250','L0251','label']\n",
    "cat_list = ['L0005','L0006','L0007','L0009','L0010','L0013','L0014','L0015','L0016','L0020','L0022','L0023','L0026','L0030','L0033','L0034','L0035','L0036','L0037','L0038','L0039','L0040','L0041','L0042','L0043','L0044','L0049','L0050','L0052','L0053','L0054','L0055','L0061','L0070','L0071','L0072','L0073','L0074','L0075','L0076','L0077','L0078','L0079','L0080','L0081','L0082','L0083','L0112','L0113','L0118','L0119','L0121','L0155','L0156','L0157','L0158','L0159','L0160','L0161','L0162','L0163','L0164','L0165','L0166','L0167','L0168','L0169','L0172','L0173','L0174','L0175','L0176','L0177','L0200','L0221','L0222','L0223','L0224','L0225','L0226','L0227','L0228','L0229','L0230','L0231','L0232','L0233','L0234','L0237','L0238','L0248','L0249','L0252','L0253','L0254','L0255','L0256']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:,useful_list]\n",
    "df = str_indexlookup(df)\n",
    "df = df.dropna(axis = 1,thresh = df.shape[0]*0.6)\n",
    "df = df.fillna(method='ffill')\n",
    "cat_list = list(set(cat_list).intersection(set(df.columns.values.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_train = df.iloc[:,1:df.shape[1]-1]# 设置训练集特征\n",
    "y_train = df.iloc[:,df.shape[1]-1]  # 设置训练集标签\n",
    "#划分测试机训练集\n",
    "#l_train, l_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = 1\n",
    "mcw=1/pow(y_train.sum(),0.5)\n",
    "lgb_train = lgb.Dataset(l_train, label = y_train, silent=True)\n",
    "                        #feature_name = df_xsmo.columns.values.tolist(),\n",
    "                        #categorical_feature = cat_list)\n",
    "#计算scale_pos_weight\n",
    "scale_pos_weight = y_train.sum()/y_train.shape[0]\n",
    "#设置lgb模型\n",
    "bst = lgb.LGBMClassifier(objective='binary'\n",
    "                            ,num_leaves=32\n",
    "                            ,learning_rate=0.05\n",
    "                            ,num_iterations=2000\n",
    "                            ,max_depth=5\n",
    "                            ,metric='auc'\n",
    "                            ,feature_fraction=0.8\n",
    "                            ,bagging_fraction = 0.8\n",
    "                            ,bagging_freq = 5\n",
    "                            ,pos_bagging_fraction = 1\n",
    "                            ,neg_bagging_fraction = scale_pos_weight\n",
    "                            ,n_jobs=-1\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------开始第一次迭代轮数计算-------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\python\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:430: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "D:\\Program\\python\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:741: UserWarning: silent keyword has been found in `params` and will be ignored.\n",
      "Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tcv_agg's binary_logloss: 0.127757 + 0.000409845\n",
      "[100]\tcv_agg's binary_logloss: 0.1145 + 0.000385114\n",
      "[150]\tcv_agg's binary_logloss: 0.110846 + 0.000458817\n",
      "[200]\tcv_agg's binary_logloss: 0.108789 + 0.000348155\n",
      "[250]\tcv_agg's binary_logloss: 0.107534 + 0.000369614\n",
      "[300]\tcv_agg's binary_logloss: 0.10675 + 0.000273892\n",
      "[350]\tcv_agg's binary_logloss: 0.10617 + 0.000335198\n",
      "[400]\tcv_agg's binary_logloss: 0.105677 + 0.000303406\n",
      "[450]\tcv_agg's binary_logloss: 0.105281 + 0.000224648\n",
      "[500]\tcv_agg's binary_logloss: 0.104907 + 0.000230168\n",
      "[550]\tcv_agg's binary_logloss: 0.104626 + 0.000270899\n",
      "[600]\tcv_agg's binary_logloss: 0.104274 + 0.000373149\n",
      "[650]\tcv_agg's binary_logloss: 0.104067 + 0.000401224\n",
      "[700]\tcv_agg's binary_logloss: 0.103982 + 0.000640495\n",
      "-------------------第一次迭代轮数计算结束-------------------\n"
     ]
    }
   ],
   "source": [
    "print('-------------------开始第一次迭代轮数计算-------------------')\n",
    "begintime=time.perf_counter()\n",
    "lgb_cv_fit(bst)\n",
    "endtime=time.perf_counter()\n",
    "print('-------------------第一次迭代轮数计算结束-------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_num_iterations: 678\n",
      "best_cv_score: 0.1039289280403803\n",
      "耗时： 501.01696949695526\n"
     ]
    }
   ],
   "source": [
    "print('best_num_iterations:',len(cv_results['binary_logloss-mean']))\n",
    "print('best_cv_score:', cv_results['binary_logloss-mean'][-1])\n",
    "print ('耗时：',endtime-begintime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\python\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "D:\\Program\\python\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:741: UserWarning: silent keyword has been found in `params` and will be ignored.\n",
      "Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[108,\n",
       " 9,\n",
       " 3940,\n",
       " 121,\n",
       " 658,\n",
       " 719,\n",
       " 974,\n",
       " 245,\n",
       " 1804,\n",
       " 1511,\n",
       " 239,\n",
       " 4,\n",
       " 208,\n",
       " 97,\n",
       " 52,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 19,\n",
       " 191,\n",
       " 445,\n",
       " 52,\n",
       " 37,\n",
       " 25,\n",
       " 55,\n",
       " 49,\n",
       " 53,\n",
       " 401,\n",
       " 10,\n",
       " 0,\n",
       " 254,\n",
       " 273,\n",
       " 958,\n",
       " 59,\n",
       " 37,\n",
       " 22,\n",
       " 16,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 25,\n",
       " 0,\n",
       " 105,\n",
       " 217,\n",
       " 55,\n",
       " 159,\n",
       " 6,\n",
       " 195,\n",
       " 260,\n",
       " 88,\n",
       " 188,\n",
       " 379,\n",
       " 193,\n",
       " 256,\n",
       " 216,\n",
       " 236,\n",
       " 223,\n",
       " 271,\n",
       " 210,\n",
       " 2,\n",
       " 46,\n",
       " 38,\n",
       " 134,\n",
       " 355,\n",
       " 119,\n",
       " 85,\n",
       " 92,\n",
       " 72,\n",
       " 0,\n",
       " 248,\n",
       " 319,\n",
       " 423,\n",
       " 498,\n",
       " 511,\n",
       " 642,\n",
       " 8,\n",
       " 67,\n",
       " 0,\n",
       " 25,\n",
       " 332,\n",
       " 151,\n",
       " 312,\n",
       " 173,\n",
       " 987,\n",
       " 0,\n",
       " 0,\n",
       " 114,\n",
       " 365,\n",
       " 406,\n",
       " 355,\n",
       " 540,\n",
       " 73,\n",
       " 303,\n",
       " 310,\n",
       " 195,\n",
       " 152,\n",
       " 154,\n",
       " 247,\n",
       " 249,\n",
       " 135,\n",
       " 0,\n",
       " 26,\n",
       " 275,\n",
       " 139,\n",
       " 50,\n",
       " 22,\n",
       " 102,\n",
       " 53,\n",
       " 130,\n",
       " 30,\n",
       " 0,\n",
       " 6,\n",
       " 292,\n",
       " 292,\n",
       " 258,\n",
       " 299,\n",
       " 334,\n",
       " 350,\n",
       " 268,\n",
       " 520,\n",
       " 1019,\n",
       " 1071,\n",
       " 334,\n",
       " 240,\n",
       " 279,\n",
       " 254,\n",
       " 258,\n",
       " 235,\n",
       " 269,\n",
       " 214,\n",
       " 218,\n",
       " 254,\n",
       " 120,\n",
       " 156,\n",
       " 210,\n",
       " 528,\n",
       " 366,\n",
       " 149,\n",
       " 239,\n",
       " 167,\n",
       " 479,\n",
       " 185,\n",
       " 7,\n",
       " 9,\n",
       " 173,\n",
       " 608,\n",
       " 426,\n",
       " 1,\n",
       " 12,\n",
       " 201,\n",
       " 146,\n",
       " 2,\n",
       " 14,\n",
       " 0,\n",
       " 17,\n",
       " 174,\n",
       " 0,\n",
       " 0,\n",
       " 323,\n",
       " 399,\n",
       " 393,\n",
       " 409,\n",
       " 165,\n",
       " 152,\n",
       " 255,\n",
       " 214,\n",
       " 273,\n",
       " 207,\n",
       " 353,\n",
       " 356,\n",
       " 23,\n",
       " 12,\n",
       " 547,\n",
       " 330,\n",
       " 225,\n",
       " 0,\n",
       " 369,\n",
       " 180,\n",
       " 0,\n",
       " 0,\n",
       " 132,\n",
       " 212,\n",
       " 211,\n",
       " 311,\n",
       " 28,\n",
       " 50,\n",
       " 44,\n",
       " 114,\n",
       " 586,\n",
       " 667,\n",
       " 918,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 529,\n",
       " 613,\n",
       " 835,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 188,\n",
       " 600,\n",
       " 610,\n",
       " 1355,\n",
       " 35,\n",
       " 162,\n",
       " 239,\n",
       " 221,\n",
       " 721,\n",
       " 0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#挑选无用特征\n",
    "param = bst.get_params()\n",
    "lgb_train = lgb.Dataset(l_train, label = y_train, silent=True)\n",
    "                        #feature_name = df_xsmo.columns.values.tolist(),\n",
    "                        #categorical_feature = cat_list)\n",
    "base_model=lgb.train(param,lgb_train)\n",
    "\n",
    "list(base_model.feature_importance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     feature_importance   name\n",
      "0                   108  L0006\n",
      "1                     9  L0007\n",
      "2                  3940  L0009\n",
      "3                   121  L0010\n",
      "4                   658  L0014\n",
      "5                   719  L0016\n",
      "6                   974  L0020\n",
      "7                   245  L0022\n",
      "8                  1804  L0023\n",
      "9                  1511  L0026\n",
      "10                  239  L0030\n",
      "11                    4  L0033\n",
      "12                  208  L0034\n",
      "13                   97  L0035\n",
      "14                   52  L0036\n",
      "15                    0  L0038\n",
      "16                    0  L0039\n",
      "17                    0  L0040\n",
      "18                    0  L0041\n",
      "19                   19  L0042\n",
      "20                  191  L0043\n",
      "21                  445  L0044\n",
      "22                   52  L0049\n",
      "23                   37  L0050\n",
      "24                   25  L0052\n",
      "25                   55  L0053\n",
      "26                   49  L0054\n",
      "27                   53  L0055\n",
      "28                  401  L0061\n",
      "29                   10  L0070\n",
      "..                  ...    ...\n",
      "181                 132  L0201\n",
      "182                 212  L0202\n",
      "183                 211  L0203\n",
      "184                 311  L0204\n",
      "185                  28  L0205\n",
      "186                  50  L0206\n",
      "187                  44  L0207\n",
      "188                 114  L0208\n",
      "189                 586  L0209\n",
      "190                 667  L0210\n",
      "191                 918  L0211\n",
      "192                   0  L0212\n",
      "193                   0  L0213\n",
      "194                   0  L0214\n",
      "195                 529  L0215\n",
      "196                 613  L0216\n",
      "197                 835  L0217\n",
      "198                   0  L0218\n",
      "199                   0  L0219\n",
      "200                   0  L0220\n",
      "201                 188  L0239\n",
      "202                 600  L0240\n",
      "203                 610  L0241\n",
      "204                1355  L0242\n",
      "205                  35  L0243\n",
      "206                 162  L0244\n",
      "207                 239  L0245\n",
      "208                 221  L0246\n",
      "209                 721  L0250\n",
      "210                   0  L0251\n",
      "\n",
      "[211 rows x 2 columns]\n",
      "     feature_importance   name\n",
      "210                   0  L0251\n",
      "69                    0  L0200\n",
      "78                    0  L0229\n",
      "85                    0  L0238\n",
      "86                    0  L0249\n",
      "101                   0  L0093\n",
      "111                   0  L0103\n",
      "42                    0  L0083\n",
      "39                    0  L0080\n",
      "38                    0  L0079\n",
      "154                   0  L0152\n",
      "157                   0  L0170\n",
      "158                   0  L0171\n",
      "176                   0  L0195\n",
      "18                    0  L0041\n",
      "17                    0  L0040\n",
      "30                    0  L0071\n",
      "15                    0  L0038\n",
      "200                   0  L0220\n",
      "199                   0  L0219\n",
      "198                   0  L0218\n",
      "194                   0  L0214\n",
      "193                   0  L0213\n",
      "16                    0  L0039\n",
      "192                   0  L0212\n",
      "179                   0  L0198\n",
      "180                   0  L0199\n",
      "148                   1  L0146\n",
      "60                    2  L0167\n",
      "152                   2  L0150\n",
      "..                  ...    ...\n",
      "21                  445  L0044\n",
      "141                 479  L0139\n",
      "73                  498  L0224\n",
      "74                  511  L0225\n",
      "120                 520  L0114\n",
      "136                 528  L0134\n",
      "195                 529  L0215\n",
      "91                  540  L0256\n",
      "173                 547  L0192\n",
      "189                 586  L0209\n",
      "202                 600  L0240\n",
      "146                 608  L0144\n",
      "203                 610  L0241\n",
      "196                 613  L0216\n",
      "75                  642  L0226\n",
      "4                   658  L0014\n",
      "190                 667  L0210\n",
      "5                   719  L0016\n",
      "209                 721  L0250\n",
      "197                 835  L0217\n",
      "191                 918  L0211\n",
      "33                  958  L0074\n",
      "6                   974  L0020\n",
      "84                  987  L0237\n",
      "121                1019  L0116\n",
      "122                1071  L0117\n",
      "204                1355  L0242\n",
      "9                  1511  L0026\n",
      "8                  1804  L0023\n",
      "2                  3940  L0009\n",
      "\n",
      "[211 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#print(base_model.feature_importance())\n",
    "#print(base_model.feature_name())\n",
    "feature_df = pd.DataFrame(list(base_model.feature_importance()))\n",
    "feature_df['name'] = pd.DataFrame(list(base_model.feature_name()))\n",
    "feature_df.rename(columns = {0:'feature_importance'},inplace=True)\n",
    "print(feature_df)\n",
    "print(feature_df.sort_values(by = 'feature_importance',ascending =True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     feature_importance   name\n",
      "2                  3940  L0009\n",
      "8                  1804  L0023\n",
      "9                  1511  L0026\n",
      "204                1355  L0242\n",
      "122                1071  L0117\n",
      "121                1019  L0116\n",
      "84                  987  L0237\n",
      "6                   974  L0020\n",
      "33                  958  L0074\n",
      "191                 918  L0211\n",
      "197                 835  L0217\n",
      "209                 721  L0250\n",
      "5                   719  L0016\n",
      "190                 667  L0210\n",
      "4                   658  L0014\n",
      "75                  642  L0226\n",
      "196                 613  L0216\n",
      "203                 610  L0241\n",
      "146                 608  L0144\n",
      "202                 600  L0240\n",
      "189                 586  L0209\n",
      "173                 547  L0192\n",
      "91                  540  L0256\n",
      "195                 529  L0215\n",
      "136                 528  L0134\n",
      "120                 520  L0114\n",
      "74                  511  L0225\n",
      "73                  498  L0224\n",
      "141                 479  L0139\n",
      "21                  445  L0044\n",
      "..                  ...    ...\n",
      "152                   2  L0150\n",
      "60                    2  L0167\n",
      "148                   1  L0146\n",
      "194                   0  L0214\n",
      "15                    0  L0038\n",
      "198                   0  L0218\n",
      "16                    0  L0039\n",
      "199                   0  L0219\n",
      "17                    0  L0040\n",
      "200                   0  L0220\n",
      "18                    0  L0041\n",
      "30                    0  L0071\n",
      "180                   0  L0199\n",
      "193                   0  L0213\n",
      "85                    0  L0238\n",
      "154                   0  L0152\n",
      "157                   0  L0170\n",
      "158                   0  L0171\n",
      "111                   0  L0103\n",
      "101                   0  L0093\n",
      "86                    0  L0249\n",
      "78                    0  L0229\n",
      "192                   0  L0212\n",
      "69                    0  L0200\n",
      "176                   0  L0195\n",
      "179                   0  L0198\n",
      "42                    0  L0083\n",
      "39                    0  L0080\n",
      "38                    0  L0079\n",
      "210                   0  L0251\n",
      "\n",
      "[211 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(feature_df.sort_values(by = 'feature_importance',ascending =False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#挑选无用特征\n",
    "param = bst.get_params()\n",
    "lgb_train = lgb.Dataset(l_train, label = y_train, silent=True)\n",
    "                        #feature_name = df_xsmo.columns.values.tolist(),\n",
    "                        #categorical_feature = cat_list)\n",
    "base_model=lgb.train(param,lgb_train)\n",
    "use_fea = list(set(list(range(l_train.shape[1])))-set(lookup_feaim0()))\n",
    "X_refea = l_train.iloc[:,use_fea]# 设置剔除无用特征训练集特征\n",
    "y_refea = df.iloc[:,df.shape[1]-1] # 设置训练集标签\n",
    "cat_refea_list = list(set(list(set(cat_list).intersection(set(X_refea.columns.values.tolist())))) - set(l_train.iloc[:,lookup_feaim0()].columns.values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_refea, label = y_refea, \n",
    "                        silent=True,\n",
    "                        feature_name = X_refea.columns.values.tolist(),\n",
    "                        categorical_feature = cat_refea_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------开始第二次迭代轮数计算-------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\python\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:430: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "D:\\Program\\python\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tcv_agg's binary_logloss: 0.126136 + 0.000452769\n",
      "[100]\tcv_agg's binary_logloss: 0.113772 + 0.000548939\n",
      "[150]\tcv_agg's binary_logloss: 0.111946 + 0.000759062\n",
      "[200]\tcv_agg's binary_logloss: 0.111147 + 0.000703343\n",
      "[250]\tcv_agg's binary_logloss: 0.11048 + 0.000581086\n",
      "[300]\tcv_agg's binary_logloss: 0.110304 + 0.000560051\n",
      "[350]\tcv_agg's binary_logloss: 0.109936 + 0.000724775\n",
      "[400]\tcv_agg's binary_logloss: 0.109672 + 0.000653907\n",
      "[450]\tcv_agg's binary_logloss: 0.109606 + 0.000634661\n",
      "[500]\tcv_agg's binary_logloss: 0.109492 + 0.000568234\n",
      "[550]\tcv_agg's binary_logloss: 0.109339 + 0.000551759\n",
      "[600]\tcv_agg's binary_logloss: 0.109226 + 0.000600133\n",
      "[650]\tcv_agg's binary_logloss: 0.109145 + 0.000612253\n",
      "[700]\tcv_agg's binary_logloss: 0.109047 + 0.000571636\n",
      "[750]\tcv_agg's binary_logloss: 0.108933 + 0.000496813\n",
      "[800]\tcv_agg's binary_logloss: 0.108809 + 0.000521196\n",
      "[850]\tcv_agg's binary_logloss: 0.108759 + 0.000535281\n",
      "[900]\tcv_agg's binary_logloss: 0.108761 + 0.00050262\n",
      "[950]\tcv_agg's binary_logloss: 0.108699 + 0.000543595\n",
      "[1000]\tcv_agg's binary_logloss: 0.108662 + 0.000541945\n",
      "[1050]\tcv_agg's binary_logloss: 0.108625 + 0.000580119\n",
      "[1100]\tcv_agg's binary_logloss: 0.108611 + 0.000563678\n",
      "[1150]\tcv_agg's binary_logloss: 0.108638 + 0.000597437\n",
      "best_n_estimators: 1112\n",
      "best_cv_score: 0.10860313765005696\n",
      "耗时： 767.18490690963\n",
      "-------------------第二次迭代轮数计算结束-------------------\n"
     ]
    }
   ],
   "source": [
    "print('-------------------开始第二次迭代轮数计算-------------------')\n",
    "begintime=time.perf_counter()\n",
    "lgb_cv_fit(bst)\n",
    "endtime=time.perf_counter()\n",
    "print('best_n_estimators:',len(cv_results['binary_logloss-mean']))\n",
    "print('best_cv_score:', cv_results['binary_logloss-mean'][-1])\n",
    "print ('耗时：',endtime-begintime)\n",
    "print('-------------------第二次迭代轮数计算结束-------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------开始搜索最佳超参数-------------------\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "D:\\Program\\python\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed: 241.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "耗时： 14911.300263607827\n",
      "-------------------最佳超参数搜索结束-------------------\n"
     ]
    }
   ],
   "source": [
    "params_test1={\n",
    "    'n_estimators':[len(cv_results['binary_logloss-mean'])]\n",
    "    ,'learning_rate':np.arange(0.01,0.2,0.01)\n",
    "    ,'min_child_weight':[mcw]\n",
    "    #,'min_child_samples': [18,19,20,21,22]\n",
    "    ,'max_depth': np.arange(3,8,1)\n",
    "    ,'num_leaves':np.arange(6,260,20)\n",
    "    ,'bagging_fraction': [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    ,'bagging_freq':[5]\n",
    "    ,'pos_bagging_fraction':[1]\n",
    "    ,'neg_bagging_fraction':[scale_pos_weight]\n",
    "    ,'reg_alpha':np.arange(0,4,0.5)\n",
    "    ,'reg_lambda':np.arange(0,4,0.5)\n",
    "}\n",
    "clf = RandomizedSearchCV(estimator=bst, \n",
    "                              param_distributions=params_test1, \n",
    "                              scoring='f1', \n",
    "                              cv=5, \n",
    "                              verbose=1\n",
    "                              )\n",
    "#clf = BayesianOptimization(bst,params_test1,random_state=7)\n",
    "print('-------------------开始搜索最佳超参数-------------------')\n",
    "begintime=time.perf_counter()\n",
    "clf.fit(X_refea, y_refea)\n",
    "#clf.maximize(init_points=10, n_iter=30, acq='ei', xi=0.0)\n",
    "endtime=time.perf_counter()\n",
    "clf.score, clf.best_params_, clf.best_score_#根据设置的测试参数，计算出最优模型参数\n",
    "print ('耗时：',endtime-begintime)\n",
    "print('-------------------最佳超参数搜索结束-------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train_refea = lgb.Dataset(X_refea, label = y_refea, \n",
    "                        silent=True)\n",
    "                        #feature_name = df_xsmo_refea.columns.values.tolist(),\n",
    "                        #categorical_feature = cat_refea_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\python\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3044: DtypeWarning: Columns (1,13,15,17,18,19,34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "D:\\Program\\python\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "l_test = pd.read_csv(train_savepath + '/user_ext_test.csv')\n",
    "l_test = str_indexlookup(l_test)\n",
    "l_test = l_test.iloc[:,use_fea]\n",
    "y_test = pd.read_csv(train_savepath + '/y_test.csv')\n",
    "\n",
    "param = clf.best_params_\n",
    "savemodel=lgb.train(param,lgb_train_refea)\n",
    "savemodel.save_model(model_savepath+'lgb_subs_model_smo')\n",
    "bst = lgb.Booster(model_file=model_savepath+'lgb_subs_model_smo')\n",
    "ypred = bst.predict(l_test, num_iteration=bst.best_iteration)\n",
    "df_ypred = pd.DataFrame(ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\python\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  del sys.path[0]\n",
      "D:\\Program\\python\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "D:\\Program\\python\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Program\\python\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count  label precision     recall    实际订购率       f1\n",
      "Kmeans                                                     \n",
      "0星      32671     37   0.4975%  100.0000%  0.1133%  0.9901%\n",
      "1星      76941    833   0.5721%   96.3000%  1.0826%  1.1374%\n",
      "2星      49891    110   0.1423%   13.0000%  0.2205%  0.2814%\n",
      "3星      22346     14   0.0482%    2.0000%  0.0627%  0.0941%\n",
      "4星      19150      6   0.0313%    0.6000%  0.0313%  0.0596%\n"
     ]
    }
   ],
   "source": [
    "#对预测结果分层\n",
    "k_clus = int(5)\n",
    "\n",
    "df1 = pd.DataFrame(ypred)\n",
    "estimator = KMeans(n_clusters=k_clus)\n",
    "estimator.fit(df1)\n",
    "label_pred = estimator.labels_ #获取聚类标签\n",
    "centroids = estimator.cluster_centers_ #获取聚类中心\n",
    "df1['Kmeans'] = label_pred\n",
    "df = pd.DataFrame(df1)\n",
    "#根据预测概率，从高到低改变聚类标签\n",
    "for i in range(k_clus):\n",
    "    df['Kmeans'].ix[df['Kmeans'] ==i]=str(sorted(centroids).index(centroids[i]))+\"星\"\n",
    "#计算各个阈值的pre,re,f1\n",
    "#df['label'] = y_test_smo\n",
    "#df['label'] = y_test.values\n",
    "df['label'] = y_test\n",
    "#label转换\n",
    "df['label'].loc[df['label']==1] = 'a'\n",
    "df['label'].loc[df['label']==0] = 'b'\n",
    "df['label'].loc[df['label']=='a'] = 0\n",
    "df['label'].loc[df['label']=='b'] = 1\n",
    "\n",
    "df['count'] = 1\n",
    "df_res=pd.pivot_table(df, index=['Kmeans'],\n",
    "    values = ['count','label'],\n",
    "    aggfunc = {'count': np.sum,'label':np.sum})\n",
    "df_res['precision'] = ''\n",
    "df_res['recall'] = ''\n",
    "df_res['实际订购率'] = df_res['label']/df_res['count']\n",
    "count_list = list(df_res['count'].values)\n",
    "label_list = list(df_res['label'].values)\n",
    "for i in range(k_clus):\n",
    "    df_res['precision'][i] = sum(label_list[i:k_clus])/sum(count_list[i:k_clus])\n",
    "    df_res['recall'][i] = sum(label_list[i:k_clus])/sum(label_list[0:k_clus])\n",
    "df_res['f1'] = 2*df_res['precision']*df_res['recall']/(df_res['precision']+df_res['recall'])\n",
    "df_res['precision'] =df_res['precision'].apply(lambda x: '%.4f%%' % (x*100))\n",
    "df_res['recall'] =df_res['recall'].apply(lambda x: '%.4f%%' % (x*100))\n",
    "df_res['f1'] =df_res['f1'].apply(lambda x: '%.4f%%' % (x*100))\n",
    "df_res['实际订购率'] =df_res['实际订购率'].apply(lambda x: '%.4f%%' % (x*100))\n",
    "print(df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.to_csv(result_path+'res_smote1.csv')\n",
    "df_ypred.to_csv(result_path+'res_pre1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
